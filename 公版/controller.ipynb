{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c6c43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from model.ipynb\n",
      "importing Jupyter notebook from view.ipynb\n"
     ]
    }
   ],
   "source": [
    "import IpynbImporter\n",
    "import model as model\n",
    "import view as view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee9eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5 import QtWidgets\n",
    "from PyQt5.QtWebEngineWidgets import QWebEngineView, QWebEnginePage\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pymysql\n",
    "import datetime\n",
    "from apscheduler.triggers.cron import CronTrigger\n",
    "# apscheduler 裡的 qt.py  第 37 行加這個   wait_seconds = int(wait_seconds) ，wait_seconds：當前距離下次任務啟動的時間差 (秒數)\n",
    "from apscheduler.schedulers.qt import QtScheduler\n",
    "from apscheduler.jobstores.base import ConflictingIdError\n",
    "import ssl\n",
    "import json\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a1b96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# file directory\n",
    "# 資料檔案\n",
    "path = os.getcwd()\n",
    "data_file_path = 'data_file'\n",
    "data_file_path = os.path.join(path, data_file_path)\n",
    "if not os.path.exists(data_file_path):\n",
    "    os.mkdir(data_file_path)\n",
    "# 設定檔案\n",
    "setting_file_path = 'setting_file'\n",
    "setting_file_path = os.path.join(path, setting_file_path)\n",
    "if not os.path.exists(setting_file_path):\n",
    "    os.mkdir(setting_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0db9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeError(BaseException, ):\n",
    "    def __init__(self, error_str):\n",
    "        self.text = error_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf08a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class controller(view.Ui_GUI_crawler):\n",
    "    def __init__(self,):\n",
    "        self.is_success_connect_db=False\n",
    "        self.db_dual_store=False\n",
    "        self.db_datetime_store='no'\n",
    "        self.schedule_crawler_list=[]\n",
    "        self.app = QtWidgets.QApplication(sys.argv)\n",
    "        self.MainWindow = QtWidgets.QMainWindow()\n",
    "        self.setupUi(self.MainWindow)\n",
    "        self.connect()\n",
    "        file_list_url = self.get_file_directory(\"url\")\n",
    "        if file_list_url != []:\n",
    "            self.url_comboBox.addItems(file_list_url)\n",
    "        file_list_tag = self.get_file_directory(\"tag\")\n",
    "        if file_list_tag != []:\n",
    "            self.tag_comboBox.addItems(file_list_tag)\n",
    "        file_list_schedule = self.get_file_directory(\"schedule\")\n",
    "        if file_list_schedule != []:\n",
    "            self.schedule_load_setting_comboBox.addItems(file_list_schedule)\n",
    "        \n",
    "    def connect(self):\n",
    "        self.before_show_data.toggled.connect(lambda: self.change_show(\"before\"))\n",
    "        self.before_test_data.clicked.connect(lambda: self.test_data(\"before\"))\n",
    "        self.before_preview.clicked.connect(self.start_before)\n",
    "        self.before_unknown.toggled.connect(self.allow_input)\n",
    "        \n",
    "        self.url_test_data.clicked.connect(lambda: self.test_data(\"url\"))\n",
    "        self.url_preview.clicked.connect(self.start_url_preview)\n",
    "        self.url_exec.clicked.connect(self.start_url_exec)\n",
    "        self.url_save_setting.clicked.connect(lambda: self.save_setting(\"url\"))\n",
    "        self.url_load_setting.clicked.connect(lambda: self.load_setting(\"url\"))\n",
    "        self.url_show_data.toggled.connect(lambda: self.change_show(\"url\"))\n",
    "        self.url_db_setting.clicked.connect(lambda: self.check_column(\"url\"))\n",
    "        \n",
    "        self.tag_test_data.clicked.connect(lambda: self.test_data(\"tag\"))\n",
    "        self.tag_preview.clicked.connect(self.start_tag_preview)\n",
    "        self.tag_next_page.clicked.connect(self.go_next_page)\n",
    "        self.tag_exec.clicked.connect(self.start_tag_exec)\n",
    "        self.tag_save_setting.clicked.connect(lambda: self.save_setting(\"tag\"))\n",
    "        self.tag_load_setting.clicked.connect(lambda: self.load_setting(\"tag\"))\n",
    "        self.tag_show_data.toggled.connect(lambda: self.change_show(\"tag\"))\n",
    "        self.tag_db_setting.clicked.connect(lambda: self.check_column(\"tag\"))\n",
    "        \n",
    "        self.db_test_connect.clicked.connect(self.test_connect)\n",
    "        self.db_datetime.clicked.connect(self.db_datetime_show)\n",
    "        self.db_dual.clicked.connect(self.insert_cover)\n",
    "        self.db_day.toggled.connect(self.datetime_status)\n",
    "        \n",
    "        self.schedule_day.toggled.connect(self.schedule_week_button_setting)\n",
    "        self.schedule_create.clicked.connect(self.creat_job)\n",
    "        self.schedule_show.clicked.connect(self.show_job)\n",
    "        self.schedule_delete.clicked.connect(self.delete_job)\n",
    "        self.schedule_exec_all.clicked.connect(self.exec_job)\n",
    "        self.schedule_show_search.clicked.connect(self.show_job_partial)\n",
    "        self.schedule_delete_search.clicked.connect(self.delete_job_partial)\n",
    "        self.schedule_exec_all_search.clicked.connect(self.exec_job_partial)\n",
    "    def start_before(self):\n",
    "        self.before_preview.setEnabled(False)\n",
    "        self.before_msg.clear()\n",
    "        if self.before_url.text().strip() ==\"\":\n",
    "            self.printf(\"發送網址 不可為空！！\", \"before\")\n",
    "            self.before_preview.setEnabled(True)\n",
    "            return\n",
    "        \n",
    "        url_attr = {'former_part':self.before_url.text().strip(), 'initial_pages':'', 'latter_part':'', 'end_pages':''}\n",
    "        \n",
    "        if self.before_domain.text().strip() == '(選填)' or self.before_domain.text().strip() == '':\n",
    "            try:\n",
    "                domain = re.search(r'//(.*?)/',url_attr['former_part']).group(1)\n",
    "                self.before_domain.setText(domain)\n",
    "            except:\n",
    "                self.printf(\"網域名稱解析錯誤，請檢查網址的前半部分，或自行輸入網域！！\", \"before\")\n",
    "                self.before_preview.setEnabled(True)\n",
    "                return\n",
    "        else:\n",
    "            domain = self.before_domain.text().strip()\n",
    "            \n",
    "        if self.before_urlencoded.isChecked():\n",
    "            Content_Type = 'application/x-www-form-urlencoded'\n",
    "        elif self.before_json.isChecked():\n",
    "            Content_Type = 'application/json'\n",
    "        elif self.before_unknown.isChecked():\n",
    "            Content_Type = self.before_unknow_input.text().strip()\n",
    "        header_attr = {'Host':domain,'Content-Type':Content_Type}\n",
    "        \n",
    "        if self.before_data.text().strip() != \"\":\n",
    "            try:\n",
    "                data = eval(self.before_data.text().strip())\n",
    "                if type(data) != dict:\n",
    "                    self.printf(\"標籤細項 型別不符，請以字典型式 {\"\":\"\",\"\":\"\"} 傳入各個 key-value！！\", \"before\")\n",
    "                    self.before_preview.setEnabled(True)\n",
    "                    return\n",
    "            except:\n",
    "                self.printf(\"標籤細項 型別不符，請以字典型式 {\"\":\"\",\"\":\"\"} 傳入各個 key-value！！\", \"before\")\n",
    "                self.before_preview.setEnabled(True)\n",
    "                return\n",
    "        \n",
    "        if self.before_GET.isChecked():\n",
    "            method = \"GET\"\n",
    "        elif self.before_POST.isChecked():\n",
    "            method = \"POST\"\n",
    "        \n",
    "        if \"my_test_crawler\" not in str(dir(self)):\n",
    "            self.my_test_crawler = model.site_url_Spider()\n",
    "        self.my_test_crawler.update_attr('Untitled', header_attr, url_attr, '', '', '', data, method)\n",
    "        self.printf(\"參數成功接收、實例化爬蟲完成，等待爬取...\", \"before\") \n",
    "        try:\n",
    "            self.my_test_crawler.before_craw()\n",
    "        except Exception as ex:\n",
    "            if 'Cloudflare' in str(ex):\n",
    "                wording = 'Cloudflare 擋住了請求！'\n",
    "            self.printf(\"爬取失敗：\" + wording, \"before\")\n",
    "            self.before_preview.setEnabled(True)\n",
    "            return\n",
    "        self.printf(\"爬取完成\", \"before\")\n",
    "        if self.before_show_html.isChecked():\n",
    "            self.printf(\"正在加載 html ...\", \"before\") \n",
    "            self.before_html_browser.setHtml(self.my_test_crawler.html)\n",
    "            self.printf(\"加載完畢\", 'before') \n",
    "        elif self.before_show_data.isChecked():\n",
    "            self.printf(\"等待將 cookies 資料顯示出來...\", \"before\") \n",
    "            self.before_html_browser.setHtml(\"<div>\" + self.my_test_crawler.cookies.replace('), Cookie(','),<br>Cookie(') + \"<div>\")\n",
    "            self.printf(\"顯示完成\", 'before') \n",
    "        self.before_preview.setEnabled(True)\n",
    "    def allow_input(self):\n",
    "        if self.before_unknown.isChecked():\n",
    "            self.before_unknow_input.setEnabled(True)\n",
    "        else:\n",
    "            self.before_unknow_input.setEnabled(False)\n",
    "\n",
    "\n",
    "    def get_data_site_url_Spider(self):\n",
    "        former_part = self.url_former_part.text().strip()\n",
    "        if former_part =='':\n",
    "            raise AttributeError('前半網址 不可為空！！')\n",
    "        try:\n",
    "            initial_pages = int(self.url_initial_pages.text().strip())\n",
    "        except:\n",
    "            raise AttributeError('初始頁數 請輸入正整數！！')\n",
    "        latter_part = self.url_latter_part.text().strip()\n",
    "\n",
    "        if self.url_end_pages.text().strip() =='':\n",
    "            end_pages=initial_pages\n",
    "            self.url_end_pages.setText(str(initial_pages))\n",
    "        else:\n",
    "            try:\n",
    "                end_pages = int(self.url_end_pages.text().strip())\n",
    "            except Exception as ex:\n",
    "                raise AttributeError('結束頁數 請輸入正整數！！')\n",
    "        url_attr = {'former_part':former_part, 'initial_pages':initial_pages, 'latter_part':latter_part, 'end_pages':end_pages}\n",
    "        if self.url_domain.text().strip() =='(選填)' or self.url_domain.text().strip() == '':\n",
    "            try:\n",
    "                domain = re.search(r'//(.*?)/',former_part).group(1)\n",
    "                self.url_domain.setText(domain)\n",
    "            except:\n",
    "                raise AttributeError('網域名稱解析錯誤，請檢查網址的前半部分，或自行輸入網域！！')\n",
    "        else:\n",
    "            domain = self.url_domain.text().strip()\n",
    "        if self.url_name.text().strip() == '' or self.url_name.text().strip() == '(選填)':\n",
    "            self.name = 'Untitled'\n",
    "            self.url_name.setText(self.name)\n",
    "        else:\n",
    "            self.name = self.url_name.text().strip()\n",
    "        \n",
    "        header_attr = {'Host':domain,'Content-Type':None}\n",
    "        tag_section = self.url_tag_section.text().strip()\n",
    "\n",
    "        if self.url_tag_detail.toPlainText().strip() ==\"\":\n",
    "            raise AttributeError('標籤細項 不可為空！！')\n",
    "        try:\n",
    "            tag_detail = eval(self.url_tag_detail.toPlainText().strip())\n",
    "        except:\n",
    "            raise AttributeError('標籤細項 拆分失敗，請以括號()分隔不同標籤！！')\n",
    "        if not(type(tag_detail) != list or type(tag_detail) != tuple):\n",
    "            raise AttributeError('標籤細項 型別不符，請以括號()分隔不同標籤！！')\n",
    "        if \"my_test_crawler\" not in str(dir(self)):\n",
    "            self.my_test_crawler = model.site_url_Spider()\n",
    "        self.my_test_crawler.update_attr(self.name, header_attr, url_attr, '', tag_section, tag_detail, None, None)\n",
    "        self.printf(\"參數成功接收，等待爬取...\", \"url\")  \n",
    "    def start_url_preview(self):\n",
    "        self.url_preview.setEnabled(False)\n",
    "        self.url_msg.clear()\n",
    "        try:\n",
    "            self.get_data_site_url_Spider()\n",
    "        except AttributeError as ex:\n",
    "            self.url_preview.setEnabled(True)\n",
    "            self.printf(str(ex), \"url\")\n",
    "            return\n",
    "        \n",
    "        self.my_test_crawler.test_parse(data_export = True, next_url = False)\n",
    "        self.printf(\"測試爬取完成，如資料錯誤，請檢查欲爬取資料是否存在 html 裡\", \"url\")\n",
    "        \n",
    "        if self.url_show_html.isChecked():\n",
    "            self.printf(\"等待將 html 頁面顯示出來...\", \"url\") \n",
    "            self.url_html_browser.setHtml(self.my_test_crawler.html)\n",
    "            self.printf(\"加載完畢\",'url') \n",
    "        elif self.url_show_data.isChecked():\n",
    "            self.printf(\"等待將 json 資料顯示出來...\", \"url\") \n",
    "            self.url_html_browser.setHtml(\"<div>\"+str(self.my_test_crawler.json)[2:-2].replace('}, {',',<br>')+\"<div>\")\n",
    "            self.printf(f\"顯示完成，總筆數：{len(self.my_test_crawler.json)}\",\"url\") \n",
    "        self.download_file(\"url\")\n",
    "        \n",
    "        self.url_exec.setEnabled(True)\n",
    "        self.url_preview.setEnabled(True)\n",
    "        self.url_save_setting.setEnabled(True)\n",
    "        \n",
    "        self.url_no.setEnabled(True)\n",
    "        self.url_excel.setEnabled(True)\n",
    "        self.url_json.setEnabled(True)        \n",
    "        if self.is_success_connect_db:\n",
    "            self.url_db_setting.setEnabled(True)\n",
    "    def start_url_exec(self,):\n",
    "        self.url_exec.setEnabled(False)\n",
    "        self.url_msg.clear()\n",
    "        self.url_html_browser.setHtml('')\n",
    "        try:\n",
    "            self.get_data_site_url_Spider()\n",
    "        except AttributeError as ex:\n",
    "            self.url_exec.setEnabled(True)\n",
    "            self.printf(str(ex), \"url\")\n",
    "            return\n",
    "        self.my_test_crawler.url_loop_parse()\n",
    "        self.printf(self.my_test_crawler.str, \"url\")\n",
    "        \n",
    "        if self.url_show_html.isChecked():\n",
    "            self.printf(\"等待將 html 頁面顯示出來...\", \"url\") \n",
    "            self.url_html_browser.setHtml(self.my_test_crawler.html)\n",
    "            self.printf(\"加載完畢\",'url') \n",
    "        elif self.url_show_data.isChecked():\n",
    "            self.printf(\"等待將 json 資料顯示出來...\", \"url\") \n",
    "            self.url_html_browser.setHtml(\"<div>\"+str(self.my_test_crawler.json)[2:-2].replace('}, {',',<br>')+\"<div>\")\n",
    "            self.printf(f\"顯示完成，總筆數：{len(re.findall(r'}, {',self.my_test_crawler.json))+1}\",\"url\") \n",
    "        self.download_file(\"url\")\n",
    "        self.url_exec.setEnabled(True)\n",
    "        \n",
    "    def get_data_next_tag_Spider(self):\n",
    "        former_part = self.tag_former_part.text().strip()\n",
    "        if former_part ==\"\":\n",
    "            raise AttributeError('網址 不可為空！！')\n",
    "        url_attr = {'former_part':former_part, 'initial_pages':'', 'latter_part':'', 'end_pages':''}\n",
    "        \n",
    "        if self.tag_domain.text().strip() == '(選填)' or self.tag_domain.text().strip() == '':\n",
    "            try:\n",
    "                domain = re.search(r'//(.*?)/',former_part).group(1)\n",
    "                self.tag_domain.setText(domain)\n",
    "            except:\n",
    "                raise AttributeError('網域名稱解析錯誤，請檢查網址的前半部分，或自行輸入網域！！')\n",
    "        else:\n",
    "            domain = self.tag_domain.text().strip()\n",
    "            \n",
    "        header_attr = {'Host':domain,'Content-Type':None}\n",
    "        \n",
    "        if self.tag_name.text().strip() == '' or self.tag_name.text().strip() == '(選填)':\n",
    "            self.name = 'Untitled'\n",
    "            self.tag_name.setText(self.name)\n",
    "        else:\n",
    "            self.name = self.tag_name.text().strip()\n",
    "        \n",
    "        try:\n",
    "            limit = int(self.tag_upper_limit.text().strip())\n",
    "        except:\n",
    "            raise AttributeError('跳轉上限 請輸入正整數！！')\n",
    "\n",
    "        \n",
    "        \n",
    "        if self.tag_next_tag.text().strip() ==\"\":\n",
    "            raise AttributeError('下一頁tag 不可為空！！')\n",
    "        try:\n",
    "            next_tag = eval(self.tag_next_tag.text().strip())+tuple([limit])\n",
    "        except:\n",
    "            raise AttributeError('下一頁tag 型別不符！！')\n",
    "        tag_section = self.tag_tag_section.text().strip()\n",
    "        if self.tag_tag_detail.toPlainText().strip() ==\"\":\n",
    "            raise AttributeError('標籤細項 不可為空！！')\n",
    "        try:\n",
    "            tag_detail = eval(self.tag_tag_detail.toPlainText().strip())\n",
    "        except:\n",
    "            raise AttributeError('標籤細項 拆分失敗，請以括號()分隔不同標籤！！')\n",
    "        if not(type(tag_detail) != list or type(tag_detail) != tuple):\n",
    "            raise AttributeError('標籤細項 型別不符，請以括號()分隔不同標籤')\n",
    "        if \"my_test_crawler\" not in str(dir(self)):\n",
    "            self.my_test_crawler = model.site_url_Spider()\n",
    "        self.my_test_crawler.update_attr(self.name, header_attr, url_attr, next_tag, tag_section, tag_detail, None, None)\n",
    "        self.printf(\"參數成功接收，等待爬取...\", \"tag\")  \n",
    "    def start_tag_preview(self):\n",
    "        self.tag_preview.setEnabled(False)\n",
    "        self.tag_msg.clear()\n",
    "        try:\n",
    "            self.get_data_next_tag_Spider()\n",
    "        except AttributeError as ex:\n",
    "            self.tag_preview.setEnabled(True)\n",
    "            self.printf(str(ex), \"tag\")\n",
    "            return\n",
    "        \n",
    "        self.my_test_crawler.test_parse(data_export = True, next_url = True)\n",
    "        self.printf(\"測試爬取完成，如資料錯誤，請檢查欲爬取資料是否存在 html 裡\", \"tag\")\n",
    "        \n",
    "        if self.tag_show_html.isChecked():\n",
    "            self.printf(\"等待將 html 頁面顯示出來...\", \"tag\") \n",
    "            self.tag_html_browser.setHtml(self.my_test_crawler.html)\n",
    "            self.printf(\"加載完畢\",'url') \n",
    "        elif self.tag_show_data.isChecked():\n",
    "            self.printf(\"等待將 json 資料顯示出來...\", \"tag\") \n",
    "            self.tag_html_browser.setHtml(\"<div>\"+str(self.my_test_crawler.json)[2:-2].replace('}, {',',<br>')+\"<div>\")\n",
    "            self.printf(f\"顯示完成，總筆數：{len(self.my_test_crawler.json)}\",\"tag\") \n",
    "        self.download_file(\"tag\")\n",
    "        \n",
    "        self.tag_next_url.setText(self.my_test_crawler.next_url)\n",
    "        self.tag_exec.setEnabled(True)\n",
    "        self.tag_preview.setEnabled(True)\n",
    "        self.tag_save_setting.setEnabled(True)\n",
    "        self.tag_next_page.setEnabled(True)\n",
    "        \n",
    "        self.tag_no.setEnabled(True)\n",
    "        self.tag_excel.setEnabled(True)\n",
    "        self.tag_json.setEnabled(True)        \n",
    "        if self.is_success_connect_db:\n",
    "            self.tag_db_setting.setEnabled(True)\n",
    "    def go_next_page(self):\n",
    "        self.my_test_crawler.url = self.my_test_crawler.next_url\n",
    "        self.tag_next_url.setText('')\n",
    "        self.tag_former_part.setText(self.my_test_crawler.url)\n",
    "        self.start_tag_preview()\n",
    "        \n",
    "    def start_tag_exec(self,):\n",
    "        self.tag_exec.setEnabled(False)\n",
    "        self.tag_msg.clear()\n",
    "        self.tag_html_browser.setHtml('')\n",
    "        try:\n",
    "            self.get_data_next_tag_Spider()\n",
    "        except AttributeError as ex:\n",
    "            self.tag_exec.setEnabled(True)\n",
    "            self.printf(str(ex), \"tag\")\n",
    "            return\n",
    "        self.my_test_crawler.next_loop_parse()\n",
    "        self.printf(self.my_test_crawler.str, \"tag\")\n",
    "        \n",
    "        if self.tag_show_html.isChecked():\n",
    "            self.printf(\"等待將 html 頁面顯示出來...\", \"tag\") \n",
    "            self.tag_html_browser.setHtml(self.my_test_crawler.html)\n",
    "            self.printf(\"加載完畢\",'url') \n",
    "        elif self.tag_show_data.isChecked():\n",
    "            self.printf(\"等待將 json 資料顯示出來...\", \"tag\") \n",
    "            self.tag_html_browser.setHtml(\"<div>\"+str(self.my_test_crawler.json)[2:-2].replace('}, {',',<br>')+\"<div>\")\n",
    "            self.printf(f\"顯示完成，總筆數：{len(re.findall(r'}, {',self.my_test_crawler.json))+1}\",\"tag\") \n",
    "        self.download_file(\"tag\")\n",
    "        self.tag_exec.setEnabled(True)\n",
    "    def get_file_directory(self, typee):\n",
    "        file_path = setting_file_path\n",
    "        files = os.listdir(file_path)\n",
    "        my_file_list =[]\n",
    "        if len(files) == 0:\n",
    "            self.printf(f\"當前 {file_path} 資料夾沒有可讀取檔案...\",typee) \n",
    "            return []\n",
    "        for i in files:\n",
    "            if file_path == data_file_path and (re.search(r'.txt',i) or re.search(r'.excel',i)):\n",
    "                my_file_list.append(i)\n",
    "            elif file_path == setting_file_path and re.search(r'.ini',i):\n",
    "                if typee ==\"url\" and re.search(r'url',i):\n",
    "                    my_file_list.append(i)\n",
    "                elif typee ==\"tag\" and re.search(r'tag',i):\n",
    "                    my_file_list.append(i)\n",
    "                elif typee ==\"schedule\":\n",
    "                    my_file_list.append(i)\n",
    "        if len(my_file_list) == 0:\n",
    "            self.printf(f\"當前 {file_path} 資料夾內沒有可讀取檔案...\",typee) \n",
    "            return []\n",
    "        return my_file_list\n",
    "        # xx = get_file_directory(\"url\")\n",
    "\n",
    "    def save_setting(self, typee):\n",
    "        setting_file_name = self.name + \"_setting_file\"\n",
    "        file_list = self.get_file_directory(typee)\n",
    "        x = 0\n",
    "        while True:\n",
    "            x = x + 1\n",
    "            self.file_name = typee + '_' + setting_file_name + '_' + str(x) + '.ini'\n",
    "            if self.file_name not in file_list:\n",
    "                break\n",
    "        crawler_ini = {}\n",
    "        crawler_ini['before_url'] = self.before_url.text().strip().replace('%','%%')\n",
    "        crawler_ini['before_data'] = self.before_data.text().strip().replace('%','%%')\n",
    "        crawler_ini['before_domain'] = self.before_domain.text().strip().replace('%','%%')\n",
    "        if self.before_GET.isChecked():\n",
    "            method = \"GET\"\n",
    "        elif self.before_POST.isChecked():\n",
    "            method = \"POST\"\n",
    "        crawler_ini['before_method'] = method\n",
    "        if self.before_urlencoded.isChecked():\n",
    "            Content_Type = 'application/x-www-form-urlencoded'\n",
    "        elif self.before_json.isChecked():\n",
    "            Content_Type = 'application/json'\n",
    "        elif self.before_unknown.isChecked():\n",
    "            Content_Type = self.before_unknow_input.text().strip().replace('%','%%')\n",
    "        crawler_ini['before_content_type'] = Content_Type\n",
    "        if typee ==\"url\":\n",
    "            crawler_ini['former_part'] = self.url_former_part.text().strip().replace('%','%%')\n",
    "            crawler_ini['initial_pages'] = self.url_initial_pages.text().strip().replace('%','%%')\n",
    "            crawler_ini['latter_part'] = self.url_latter_part.text().strip().replace('%','%%')\n",
    "            crawler_ini['end_pages'] = self.url_end_pages.text().strip().replace('%','%%')\n",
    "            crawler_ini['next_url'] = ''\n",
    "            crawler_ini['next_tag'] = ''\n",
    "            crawler_ini['domain'] = self.url_domain.text().strip().replace('%','%%')\n",
    "            crawler_ini['name'] = self.url_name.text().strip().replace('%','%%')\n",
    "            crawler_ini['tag_section'] = self.url_tag_section.text().strip().replace('%','%%')\n",
    "            crawler_ini['tag_detail'] = self.url_tag_detail.toPlainText().strip().replace('%','%%')\n",
    "            crawler_ini['upper_limit'] = ''\n",
    "            if self.url_excel.isChecked():\n",
    "                data_download = \"excel\"\n",
    "            elif self.url_json.isChecked():\n",
    "                data_download = \"json\"\n",
    "            elif self.url_no.isChecked():\n",
    "                data_download = \"no\"\n",
    "            elif self.url_db_setting.isChecked():\n",
    "                data_download = \"sql\"\n",
    "            crawler_ini['data_download'] = data_download\n",
    "        elif typee ==\"tag\":\n",
    "            crawler_ini['former_part'] = self.tag_former_part.text().strip().replace('%','%%')\n",
    "            crawler_ini['initial_pages'] = ''\n",
    "            crawler_ini['latter_part'] = ''\n",
    "            crawler_ini['end_pages'] = ''\n",
    "            crawler_ini['next_url'] = self.tag_next_url.text().strip().replace('%','%%')\n",
    "            crawler_ini['next_tag'] = self.tag_next_tag.text().strip().replace('%','%%')\n",
    "            crawler_ini['domain'] = self.tag_domain.text().strip().replace('%','%%')\n",
    "            crawler_ini['name'] = self.tag_name.text().strip().replace('%','%%')\n",
    "            crawler_ini['tag_section'] = self.tag_tag_section.text().strip().replace('%','%%')\n",
    "            crawler_ini['tag_detail'] = self.tag_tag_detail.toPlainText().strip().replace('%','%%')\n",
    "            crawler_ini['upper_limit'] = self.tag_upper_limit.text().strip().replace('%','%%')\n",
    "            if self.tag_excel.isChecked():\n",
    "                data_download = \"excel\"\n",
    "            elif self.tag_json.isChecked():\n",
    "                data_download = \"json\"\n",
    "            elif self.tag_no.isChecked():\n",
    "                data_download = \"no\"\n",
    "            elif self.tag_db_setting.isChecked():\n",
    "                data_download = \"sql\"\n",
    "            crawler_ini['data_download'] = data_download\n",
    "\n",
    "        crawler_ini['host'] = self.db_ip.text().strip()\n",
    "        crawler_ini['port'] = self.db_port.text().strip()\n",
    "        crawler_ini['user'] = self.db_username.text().strip()\n",
    "        crawler_ini['password'] = self.db_password.text().strip()\n",
    "        crawler_ini['db'] = self.db_name.text().strip()\n",
    "        crawler_ini['charset'] = self.db_charset.text().strip()\n",
    "        crawler_ini['autocommit'] = True\n",
    "        crawler_ini['table_name'] = self.db_table_name.text().strip()\n",
    "        crawler_ini['is_datetime'] = self.db_datetime_store\n",
    "        crawler_ini['is_cover'] = self.db_dual_store\n",
    "        model.save_setting_ini(setting_file_path + '/' + self.file_name, crawler_ini)\n",
    "        self.printf(f\"檔案保存成功，檔名：{self.file_name}，檔名請勿修改\",typee) \n",
    "    \n",
    "    \n",
    "        file_list_schedule = self.get_file_directory(\"schedule\")\n",
    "        if file_list_schedule != []:\n",
    "            self.schedule_load_setting_comboBox.clear()\n",
    "            self.schedule_load_setting_comboBox.addItems(file_list_schedule)\n",
    "            \n",
    "        file_list = self.get_file_directory(typee)\n",
    "        if typee ==\"url\":\n",
    "            self.url_comboBox.clear()\n",
    "            self.url_comboBox.addItems(file_list)\n",
    "        elif typee ==\"tag\":\n",
    "            self.tag_comboBox.clear()\n",
    "            self.tag_comboBox.addItems(file_list)\n",
    "    def load_setting(self,typee):\n",
    "        if typee ==\"url\":\n",
    "            comboBox = self.url_comboBox\n",
    "        elif typee ==\"tag\":\n",
    "            comboBox = self.tag_comboBox\n",
    "        this_file_name = comboBox.currentText().strip()\n",
    "        path_name = setting_file_path + '/' + this_file_name\n",
    "        \n",
    "        try:\n",
    "            data,data_before,db_settings,db_settings_others = model.load_setting_ini(path_name)\n",
    "            self.printf(f\"{this_file_name} 讀取成功\",typee) \n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            self.printf(f\"{this_file_name} 讀取失敗，請檢查檔案是否存在\",typee) \n",
    "            return\n",
    "        if data_before['before_url'] != '' and \"選填\" not in data_before['before_domain']:\n",
    "            self.before_url.setText(data_before['before_url'])\n",
    "            self.before_data.setText(data_before['before_data'])\n",
    "            self.before_domain.setText(data_before['before_domain'])\n",
    "            method =  data_before['before_method']\n",
    "            if method == \"GET\":\n",
    "                self.before_GET.setChecked(True)\n",
    "            elif method == \"POST\":\n",
    "                self.before_POST.setChecked(True)\n",
    "            content_type = data_before['before_content_type']\n",
    "            if content_type == 'application/x-www-form-urlencoded':\n",
    "                self.before_urlencoded.setChecked(True)\n",
    "            elif content_type == 'application/json':\n",
    "                self.before_json.setChecked(True)\n",
    "            else:\n",
    "                self.before_unknown.setChecked(True)\n",
    "                self.before_unknow_input.setText(content_type)\n",
    "            try:\n",
    "                self.start_before()\n",
    "                if self.my_test_crawler.cookies == '[]':\n",
    "                    self.printf(f\"{this_file_name} 執行前置動作，未成功獲取 cookies\",typee) \n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                self.printf(f\"{this_file_name} 執行前置動作失敗，請重新測試\",typee) \n",
    "\n",
    "        else:\n",
    "            self.printf(f\"{this_file_name} 未設定前置動作，略過\",typee) \n",
    "            \n",
    "        if typee ==\"url\":\n",
    "            self.url_former_part.setText(data['former_part'])\n",
    "            self.url_initial_pages.setText(data['initial_pages'])\n",
    "            self.url_latter_part.setText(data['latter_part'])\n",
    "            self.url_end_pages.setText(data['end_pages'])\n",
    "            self.url_domain.setText(data['domain'])\n",
    "            self.url_name.setText(data['name'])\n",
    "            self.url_tag_section.setText(data['tag_section'])\n",
    "            self.url_tag_detail.setText(data['tag_detail'])\n",
    "            try:\n",
    "                self.get_data_site_url_Spider()\n",
    "            except AttributeError as ex:\n",
    "                self.url_preview.setEnabled(True)\n",
    "                self.printf(str(ex), typee)\n",
    "                return\n",
    "        elif typee ==\"tag\":\n",
    "            self.tag_former_part.setText(data['former_part'])\n",
    "            self.tag_next_tag.setText(data['next_tag'])\n",
    "            self.tag_next_url.setText(data['next_url'])\n",
    "            self.tag_domain.setText(data['domain'])\n",
    "            self.tag_name.setText(data['name'])\n",
    "            self.tag_tag_section.setText(data['tag_section'])\n",
    "            self.tag_tag_detail.setText(data['tag_detail'])\n",
    "            self.tag_upper_limit.setText(data['upper_limit'])\n",
    "            try:\n",
    "                self.get_data_next_tag_Spider()\n",
    "            except AttributeError as ex:\n",
    "                self.tag_preview.setEnabled(True)\n",
    "                self.printf(str(ex), typee)\n",
    "                return\n",
    "    def change_show(self, typee):\n",
    "        try: \n",
    "            if typee ==\"url\":\n",
    "                if self.url_show_html.isChecked():\n",
    "                    self.printf(\"正在加載 html ...\",typee) \n",
    "                    self.url_html_browser.setHtml(self.my_test_crawler.html)\n",
    "                    self.printf(\"加載完畢\",'url') \n",
    "                elif self.url_show_data.isChecked():\n",
    "                    self.printf(\"等待將 json 資料顯示出來...\",typee) \n",
    "                    self.url_html_browser.setHtml(\"<div>\"+str(self.my_test_crawler.json)[2:-2].replace('}, {',',<br>')+\"<div>\")\n",
    "                    self.printf(f\"顯示完成，總筆數：{len(re.findall(r'}, {',self.my_test_crawler.json))+1}\",typee) \n",
    "            elif typee ==\"before\":\n",
    "                if self.before_show_html.isChecked():\n",
    "                    self.printf(\"正在加載 html ...\",typee) \n",
    "                    self.before_html_browser.setHtml(self.my_test_crawler.html)\n",
    "                    self.printf(\"加載完畢\",'before') \n",
    "                elif self.before_show_data.isChecked():\n",
    "                    self.printf(\"等待將 cookies 資料顯示出來...\", typee) \n",
    "                    self.before_html_browser.setHtml(\"<div>\" + self.my_test_crawler.cookies.replace('), Cookie(','),<br>Cookie(') + \"<div>\")\n",
    "                    self.printf(\"顯示完成\", typee) \n",
    "            elif typee ==\"tag\":\n",
    "                if self.tag_show_html.isChecked():\n",
    "                    self.printf(\"正在加載 html ...\",typee) \n",
    "                    self.tag_html_browser.setHtml(self.my_test_crawler.html)\n",
    "                    self.printf(\"加載完畢\",'url') \n",
    "                elif self.tag_show_data.isChecked():\n",
    "                    self.printf(\"等待將 json 資料顯示出來...\",typee) \n",
    "                    self.tag_html_browser.setHtml(\"<div>\"+str(self.my_test_crawler.json)[2:-2].replace('}, {',',<br>')+\"<div>\")\n",
    "                    self.printf(f\"顯示完成，總筆數：{len(re.findall(r'}, {',self.my_test_crawler.json))+1}\",typee) \n",
    "        except AttributeError:\n",
    "            pass\n",
    "        except Exception as ex:\n",
    "            self.printf('爬蟲未正確執行，請確認執行是否成功',typee)\n",
    "\n",
    "    def download_file(self, typee):\n",
    "        try:\n",
    "            result = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "            if typee ==\"url\":\n",
    "                if self.url_excel.isChecked():\n",
    "                    self_file_path = data_file_path + '/' + self.name + '_' +  result + '.xlsx'\n",
    "                    self.my_test_crawler.export_excel(self_file_path)\n",
    "                    self.printf(f\"檔案製作完成，檔案位置: {self_file_path}\", typee)\n",
    "                elif self.url_json.isChecked():\n",
    "                    self_file_path = data_file_path  + '/' + self.name + '_' +  result + '.txt'\n",
    "                    with open(self_file_path, 'a+', encoding='utf-8') as file:\n",
    "                        file.write(str(self.my_test_crawler.json))\n",
    "                        file.close()\n",
    "                    self.printf(f\"檔案製作完成，檔案位置: {self_file_path}\", typee)\n",
    "                elif self.url_db_setting.isChecked():\n",
    "                    x=0\n",
    "                    dics = json.loads(self.my_test_crawler.json)\n",
    "                    conn = pymysql.connect(**self.db_settings)\n",
    "                    print(self.db_datetime_store)\n",
    "                    with conn.cursor() as cursor:\n",
    "                        for data in dics:\n",
    "                            if self.db_datetime_store=='sec':\n",
    "                                data['Data_Datetime']=datetime.datetime.strftime(datetime.datetime.now(), \"%Y-%m-%d %H:%M:%S\")\n",
    "                            elif self.db_datetime_store=='day':\n",
    "                                data['Data_Datetime']=datetime.datetime.strftime(datetime.date.today(), \"%Y-%m-%d\")\n",
    "                            command_first = f\"INSERT INTO {self.db_settings['db']}.{self.table_name} ({', '.join(data.keys())}) VALUES \"\n",
    "                            command_second = '(\"'+ '\\\", \\\"'.join(data.values()) +'\") '\n",
    "                            if self.db_dual_store:\n",
    "                                update_query ='on DUPLICATE KEY UPDATE ' +  u', '.join([u\"{}='{}'\".format(k, v) for k, v in zip(data.keys(),data.values())])\n",
    "                                command = command_first+command_second + update_query\n",
    "                            else:\n",
    "                                command = command_first+command_second\n",
    "                            try:\n",
    "                                cursor.execute(command)\n",
    "                            except Exception as ex:\n",
    "                                self.printf(f\"{data} 存入資料庫報錯，錯誤內容: {ex}\", typee)\n",
    "                                continue\n",
    "                            x=x+1\n",
    "                    self.printf(f\"資料庫儲存完成，資料共有 {len(dics)} 筆，成功存入 {x} 筆\", typee)\n",
    "                else:\n",
    "                    return\n",
    "            elif typee ==\"tag\":\n",
    "                if self.tag_excel.isChecked():\n",
    "                    self_file_path = data_file_path + '/' + self.name + '_' +  result + '.xlsx'\n",
    "                    self.my_test_crawler.export_excel(self_file_path)\n",
    "                    self.printf(f\"檔案製作完成，檔案位置: {self_file_path}\", typee)\n",
    "                elif self.tag_json.isChecked():\n",
    "                    self_file_path = data_file_path  + '/' + self.name + '_' +  result + '.txt'\n",
    "                    with open(self_file_path, 'a+', encoding='utf-8') as file:\n",
    "                        file.write(str(self.my_test_crawler.json))\n",
    "                        file.close()\n",
    "                    self.printf(f\"檔案製作完成，檔案位置: {self_file_path}\", typee)\n",
    "                elif self.tag_db_setting.isChecked():\n",
    "                    x=0\n",
    "                    dics = json.loads(self.my_test_crawler.json)\n",
    "                    conn = pymysql.connect(**self.db_settings)\n",
    "                    with conn.cursor() as cursor:\n",
    "                        for data in dics:\n",
    "                            if self.db_datetime_store=='sec':\n",
    "                                data['Data_Datetime']=datetime.datetime.strftime(datetime.datetime.now(), \"%Y-%m-%d %H:%M:%S\")\n",
    "                            elif self.db_datetime_store=='day':\n",
    "                                data['Data_Datetime']=datetime.datetime.strftime(datetime.date.today(), \"%Y-%m-%d\")\n",
    "                            command_first = f\"INSERT INTO {self.db_settings['db']}.{self.table_name} ({', '.join(data.keys())}) VALUES \"\n",
    "                            command_second = '(\"'+ '\\\", \\\"'.join(data.values()) +'\") '\n",
    "                            if self.db_dual_store:\n",
    "                                update_query ='on DUPLICATE KEY UPDATE ' +  u', '.join([u\"{}='{}'\".format(k, v) for k, v in zip(data.keys(),data.values())])\n",
    "                                command = command_first+command_second + update_query\n",
    "                            else:\n",
    "                                command = command_first+command_second\n",
    "                            try:\n",
    "                                cursor.execute(command)\n",
    "                            except Exception as ex:\n",
    "                                self.printf(f\"{data} 存入資料庫報錯，錯誤內容: {ex}\", typee)\n",
    "                                continue\n",
    "                            x=x+1\n",
    "                    self.printf(f\"資料庫儲存完成，資料共有 {len(dics)} 筆，成功存入 {x} 筆\", typee)\n",
    "                else:\n",
    "                    return\n",
    "            \n",
    "        except AttributeError:\n",
    "            pass\n",
    "        except Exception as ex:\n",
    "            self.printf(str(ex), typee)\n",
    "    def test_connect(self):\n",
    "        if self.db_datetime.isChecked():\n",
    "            if not(self.db_day.isChecked() or self.db_sec.isChecked()):\n",
    "                self.printf('最小時間單位未選擇', 'db')\n",
    "                return\n",
    "        #self.test_data('db')\n",
    "        if self.db_ip.text().strip() =='' or self.db_port.text().strip() =='':\n",
    "            self.printf('請填入伺服器IP和端口號', 'db')\n",
    "            return\n",
    "        if self.db_table_name.text().strip() =='' or self.db_name.text().strip() =='':\n",
    "            self.printf('請填入資料庫名稱和資料表名稱', 'db')\n",
    "            return \n",
    "        if self.db_username.text().strip() =='' or self.db_password.text().strip() =='':\n",
    "            self.printf('請填入登入用帳號密碼', 'db')\n",
    "            return \n",
    "        self.db_settings = {\n",
    "        \"host\": self.db_ip.text().strip(),\n",
    "        \"port\": int(self.db_port.text().strip()),\n",
    "        \"user\": self.db_username.text().strip(),\n",
    "        \"password\": self.db_password.text().strip(),\n",
    "        \"db\": self.db_name.text().strip(),\n",
    "        \"charset\": self.db_charset.text().strip(),\n",
    "        \"autocommit\":True}\n",
    "        self.table_name = self.db_table_name.text().strip()\n",
    "        try:\n",
    "            # 建立Connection物件\n",
    "            conn = pymysql.connect(**self.db_settings)\n",
    "            # 建立Cursor物件\n",
    "            with conn.cursor(pymysql.cursors.DictCursor) as cursor:\n",
    "              #資料表相關操作\n",
    "                # % 操作符只能直接用於字串(‘123’)，列表([1,2,3])、元組\n",
    "                command = f\"SHOW COLUMNS FROM {self.db_settings['db']}.{self.table_name}\"\n",
    "                # 執行\n",
    "                cursor.execute(command)\n",
    "                table_des = cursor.fetchall()\n",
    "        except Exception as ex:\n",
    "            self.printf('資料庫連線失敗' + str(ex), 'db')\n",
    "            return\n",
    "        self.column_name_null=[i['Field']  for i in table_des if i['Null']=='YES' or (i['Null']=='NO' and'auto_increment' in i['Extra'])]\n",
    "        self.column_name_notnull=[i['Field']  for i in table_des if i['Null']=='NO' and 'auto_increment' not in i['Extra']]\n",
    "        self.printf(f\"資料庫連線成功！必填欄位名稱：{str(self.column_name_notnull)}；非必填欄位名稱：{str(self.column_name_null)}\", 'db')\n",
    "        if self.db_datetime_store!='no' and ('Data_Datetime' not in self.column_name_notnull and 'Data_Datetime' not in self.column_name_null):\n",
    "            self.printf(f\"資料庫欄位未出現 Data_Datetime，取消記錄日期時間\", 'db')\n",
    "            self.db_datetime.setChecked(False)\n",
    "            self.db_datetime_show()\n",
    "        elif self.db_datetime_store!='no':\n",
    "             self.printf(f\"資料庫欄位存在 Data_Datetime，記錄日期時間\", 'db')\n",
    "        if self.db_dual_store:\n",
    "            self.printf(f\"開啟自動更新功能\", 'db')\n",
    "        \n",
    "        self.is_success_connect_db=True\n",
    "        if self.url_exec.isEnabled():\n",
    "            self.url_db_setting.setEnabled(True)\n",
    "        if self.tag_exec.isEnabled():\n",
    "            self.tag_db_setting.setEnabled(True)\n",
    "        self.printf(' ', 'db')\n",
    "    def check_column(self, typee):\n",
    "        if typee ==\"url\":\n",
    "            if self.url_tag_detail.toPlainText().strip()=='':\n",
    "                self.printf(\"標籤設定細項設定不可為空，否則無法判斷資料庫欄位\", typee)\n",
    "                self.url_no.setChecked(True)\n",
    "                return\n",
    "            diff_set = set([i[0] for i in eval(self.url_tag_detail.toPlainText().strip())]) - set(self.column_name_null+self.column_name_notnull)\n",
    "            if len(diff_set) >0:\n",
    "                self.printf(f\"資料表欄位無法對齊：{str(diff_set)}非在資料表欄位中\", typee)\n",
    "                self.url_no.setChecked(True)\n",
    "                return\n",
    "            diff_set = set(self.column_name_notnull) - set([i[0] for i in eval(self.url_tag_detail.toPlainText().strip())])\n",
    "            if len(diff_set) >0:\n",
    "                self.printf(f\"資料表必填欄位無法滿足：{str(diff_set)} 資料表欄位沒有賦值\", typee)\n",
    "                self.url_no.setChecked(True)\n",
    "                return\n",
    "        elif typee ==\"tag\":\n",
    "            if self.tag_tag_detail.toPlainText().strip()=='':\n",
    "                self.printf(\"標籤設定細項設定不可為空，否則無法判斷資料庫欄位\", typee)\n",
    "                self.tag_no.setChecked(True)\n",
    "                return\n",
    "            diff_set = set([i[0] for i in eval(self.tag_tag_detail.toPlainText().strip())]) - set(self.column_name_null+self.column_name_notnull)\n",
    "            if len(diff_set) >0:\n",
    "                self.printf(f\"資料表欄位無法對齊：{str(diff_set)}非在資料表欄位中\", typee)\n",
    "                self.tag_no.setChecked(True)\n",
    "                return\n",
    "            diff_set = set(self.column_name_notnull) - set([i[0] for i in eval(self.tag_tag_detail.toPlainText().strip())])\n",
    "            if len(diff_set) >0:\n",
    "                self.printf(f\"資料表必填欄位無法滿足：{str(diff_set)} 資料表欄位沒有賦值\", typee)\n",
    "                self.tag_no.setChecked(True)\n",
    "                return\n",
    "        self.printf(f\"資料表欄位檢查完成！\", typee)\n",
    "    def db_datetime_show(self):\n",
    "        if self.db_datetime.isChecked():\n",
    "            self.db_day.setEnabled(True)\n",
    "            self.db_sec.setEnabled(True)\n",
    "            if self.db_day.isChecked():\n",
    "                self.db_datetime_store='day'\n",
    "            elif self.db_sec.isChecked():\n",
    "                self.db_datetime_store='sec'\n",
    "        else:\n",
    "            self.db_day.setChecked(False)\n",
    "            self.db_day.setEnabled(False)\n",
    "            self.db_sec.setChecked(False)\n",
    "            self.db_sec.setEnabled(False)\n",
    "            self.db_datetime_store='no'\n",
    "    def datetime_status(self):\n",
    "        if self.db_day.isChecked():\n",
    "            self.db_datetime_store='day'\n",
    "        elif self.db_sec.isChecked():\n",
    "            self.db_datetime_store='sec'\n",
    "    def insert_cover(self):\n",
    "        if self.db_dual.isChecked():\n",
    "            self.db_dual_store=True\n",
    "        else:\n",
    "            self.db_dual_store=False\n",
    "    def test_data(self, typee):\n",
    "        if typee == \"url\":\n",
    "            self.url_former_part.setText('https://web.pcc.gov.tw/prkms/tender/common/basic/readTenderBasic?tenderEndDate=2022%2F06%2F01&orgName=&tenderName=&searchType=basic&d-49738-p=')\n",
    "            self.url_initial_pages.setText('1')\n",
    "            self.url_latter_part.setText('&firstSearch=false&pageSize=50&radProctrgCate=&tenderId=&orgId=&tenderStartDate=2022%2F06%2F01&tenderType=TENDER_DECLARATION&dateType=isDate&tenderWay=TENDER_WAY_ALL_DECLARATION&level_1=on')\n",
    "            self.url_tag_section.setText('div#printArea table.tb_01 tr')\n",
    "            self.url_tag_detail.setText(\"[('機關名稱','td',1,'text'),('標案案號','td',2,'text'),('連結','td a ',0,'href'),('傳輸次數','td',3,'text'),('招標方式','td',4,'text')]\")\n",
    "        elif typee == \"before\":\n",
    "            self.before_url.setText(\"https://sso.teachable.com/secure/teachable_accounts/sign_in\")\n",
    "            xx={\"utf8\":\"✓\",\"authenticity_token\":\"PQYVq3q5auCLwa/Wi+UNdu3u4kMQqYSBN+u3k6Q5qpBH1O+egi+IohEBkQqH5LPa456xzGJfrddbLV9D++6srQ==\",\"teachable_account[email]\":\"teciram904@saturdata.com\",\"teachable_account[password]\":\"teciram904\",\"commit\":\"Log In\"}\n",
    "            self.before_data.setText(str(xx))\n",
    "        elif typee == \"tag\":\n",
    "            self.tag_former_part.setText('https://www.ptt.cc/bbs/LoL/index.html')\n",
    "            self.tag_next_url.setText('')\n",
    "            self.tag_next_tag.setText('(\"div.btn-group.btn-group-paging a\",1)')\n",
    "            self.tag_upper_limit.setText('9')\n",
    "            self.tag_tag_section.setText('div.r-ent')\n",
    "            self.tag_tag_detail.setText(\"[('title','div.title',0,'text'),('author','div.author',0,'text'),('date','div.date',0,'text'),('url','div.title a',0,'href')]\")\n",
    "        elif typee ==\"db\":\n",
    "            self.db_ip.setText('127.0.0.1')\n",
    "            self.db_port.setText('3306')\n",
    "            self.db_username.setText('root')\n",
    "            self.db_password.setText('As123459362')\n",
    "            self.db_name.setText('pttcrawler')\n",
    "            self.db_charset.setText('utf8mb4')\n",
    "            self.db_table_name.setText('ptt_data')\n",
    "        self.schedule_name.setText('test')\n",
    "        xx = datetime.datetime.now() + datetime.timedelta(minutes=1)\n",
    "        date_time = xx.strftime(\"%H:%M:%S\")\n",
    "        self.schedule_time.setText(date_time)\n",
    "    def schedule_week_button_setting(self):\n",
    "        if self.schedule_day.isChecked():\n",
    "            self.schedule_week_1.setEnabled(False)\n",
    "            self.schedule_week_2.setEnabled(False)\n",
    "            self.schedule_week_3.setEnabled(False)\n",
    "            self.schedule_week_4.setEnabled(False)\n",
    "            self.schedule_week_5.setEnabled(False)\n",
    "            self.schedule_week_6.setEnabled(False)\n",
    "            self.schedule_week_7.setEnabled(False)\n",
    "        elif self.schedule_week.isChecked():\n",
    "            self.schedule_week_1.setEnabled(True)\n",
    "            self.schedule_week_2.setEnabled(True)\n",
    "            self.schedule_week_3.setEnabled(True)\n",
    "            self.schedule_week_4.setEnabled(True)\n",
    "            self.schedule_week_5.setEnabled(True)\n",
    "            self.schedule_week_6.setEnabled(True)\n",
    "            self.schedule_week_7.setEnabled(True)\n",
    "    def job_do(self, ini, idd):\n",
    "        schedule_now = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        self.printf(f\"當前時間：{schedule_now}，開始執行爬蟲\", 'schedule')\n",
    "        path_name = setting_file_path + '/' + ini\n",
    "        data,data_before,db_settings,db_settings_others = model.load_setting_ini(path_name)\n",
    "        self.printf(f\"{ini} 讀取完畢\",\"schedule\") \n",
    "        \n",
    "        schedule_crawler = model.site_url_Spider()\n",
    "        if data_before['before_url'] != '' and \"選填\" not in data_before['before_domain']:\n",
    "            headers_attr = {\"Host\":data_before[\"before_domain\"], \"Content-Type\":data_before[\"before_content_type\"]}\n",
    "            url_attr = {'former_part':data_before[\"before_url\"], 'initial_pages':'', 'latter_part':'', 'end_pages':''}\n",
    "            datas = eval(data_before[\"before_data\"])\n",
    "            method = data_before[\"before_method\"]\n",
    "            schedule_crawler.update_attr(idd, headers_attr, url_attr, '', '', '', datas, method)\n",
    "            try:\n",
    "                schedule_crawler.before_craw()\n",
    "            except:\n",
    "                self.printf('前置動作執行失敗，略過', 'schedule')\n",
    "            self.printf('前置動作完成', 'schedule')\n",
    "\n",
    "        if \"url\" in ini[0:3]:\n",
    "            url_attr = {'former_part':data['former_part'], 'initial_pages':data['initial_pages'], 'latter_part':data['latter_part'], 'end_pages':data['end_pages']}\n",
    "            headers_attr = {'Host':data['domain'],'Content-Type':None}\n",
    "            schedule_crawler.update_attr(idd, headers_attr, url_attr, '', data['tag_section'], eval(data['tag_detail']), None, None)\n",
    "            schedule_crawler.url_loop_parse()\n",
    "        elif \"tag\" in ini[0:3]:\n",
    "            url_attr = {'former_part':data['former_part'], 'initial_pages':data['initial_pages'], 'latter_part':data['latter_part'], 'end_pages':data['end_pages']}\n",
    "            headers_attr = {'Host':data['domain'],'Content-Type':None}\n",
    "            limit = int(data['upper_limit'])\n",
    "            next_tag = eval(data['next_tag'])+tuple([limit])\n",
    "            schedule_crawler.update_attr(idd, headers_attr, url_attr, next_tag, data['tag_section'], eval(data['tag_detail']), None, None)\n",
    "            schedule_crawler.next_loop_parse()\n",
    "        self.printf('爬取完成', 'schedule')\n",
    "        self.printf(schedule_crawler.str, 'schedule')\n",
    "        result = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "        if data['data_download'] == 'excel':\n",
    "            self_file_path = data_file_path + '/' + idd + '_' + result + '.xlsx'\n",
    "            schedule_crawler.export_excel(self_file_path)\n",
    "            self.printf(f\"檔案製作完成，檔案位置: {self_file_path}\", 'schedule')\n",
    "        elif data['data_download'] == 'json':\n",
    "            self_file_path = data_file_path  + '/' + idd + '_' + result + '.txt'\n",
    "            with open(self_file_path, 'a+', encoding='utf-8') as file:\n",
    "                file.write(str(schedule_crawler.json))\n",
    "                file.close()\n",
    "            self.printf(f\"檔案製作完成，檔案位置: {self_file_path}\", 'schedule')\n",
    "        elif data['data_download'] == 'sql':\n",
    "            x=0\n",
    "            dics = json.loads(schedule_crawler.json)\n",
    "            conn = pymysql.connect(**db_settings)\n",
    "            with conn.cursor() as cursor:\n",
    "                for dic in dics:\n",
    "                    if db_settings_others['is_datetime']=='sec':\n",
    "                        dic['Data_Datetime']=datetime.datetime.strftime(datetime.datetime.now(), \"%Y-%m-%d %H:%M:%S\")\n",
    "                    elif db_settings_others['is_datetime']=='day':\n",
    "                        dic['Data_Datetime']=datetime.datetime.strftime(datetime.date.today(), \"%Y-%m-%d\")\n",
    "                    command_first = f\"INSERT INTO {db_settings['db']}.{db_settings_others['table_name']} ({', '.join(dic.keys())}) VALUES \"\n",
    "                    command_second = '(\"'+ '\\\", \\\"'.join(dic.values()) +'\") '\n",
    "                    if db_settings_others['is_cover']:\n",
    "                        update_query ='on DUPLICATE KEY UPDATE ' +  u', '.join([u\"{}='{}'\".format(k, v) for k, v in zip(dic.keys(),dic.values())])\n",
    "                        command = command_first+command_second + update_query\n",
    "                    else:\n",
    "                        command = command_first+command_second\n",
    "                    try:\n",
    "                        cursor.execute(command)\n",
    "                    except Exception as ex:\n",
    "                        self.printf(f\"{data} 存入資料庫報錯，錯誤內容: {ex}\", 'schedule')\n",
    "                        continue\n",
    "                    x=x+1\n",
    "            self.printf(f\"資料庫儲存完成，資料共有 {len(dics)} 筆，成功存入 {x} 筆\", 'schedule')\n",
    "        self.printf(f\"當前時間：{result}，執行爬蟲完成\", 'schedule')\n",
    "    def creat_job(self):\n",
    "        self.schedule_create.setEnabled(False)\n",
    "        if self.schedule_load_setting_comboBox.currentText().strip() == \"\":\n",
    "            self.schedule_create.setEnabled(True)\n",
    "            self.printf(\"未選擇設定檔\", 'schedule')\n",
    "            return\n",
    "        if self.schedule_name.text().strip() == \"\":\n",
    "            self.schedule_create.setEnabled(True)\n",
    "            self.printf(\"排程名稱 不可為空！！\", 'schedule')\n",
    "            return\n",
    "        if self.schedule_time.text().strip() == \"\" or \"HH:MM:SS\" in self.schedule_time.text().strip():\n",
    "            self.schedule_create.setEnabled(True)\n",
    "            self.printf(\"排程時間 不可為空！！\", 'schedule')\n",
    "            return\n",
    "        if self.schedule_week.isChecked() and not (self.schedule_week_1.isChecked() or self.schedule_week_2.isChecked() or self.schedule_week_3.isChecked() or self.schedule_week_4.isChecked() or self.schedule_week_5.isChecked() or self.schedule_week_6.isChecked() or self.schedule_week_7.isChecked()):\n",
    "            self.schedule_create.setEnabled(True)\n",
    "            self.printf(\"請選擇每周幾執行\", 'schedule')\n",
    "            return\n",
    "        \n",
    "        dayOfWeek=''\n",
    "        if self.schedule_day.isChecked():\n",
    "            dayOfWeek='0-6,'\n",
    "        elif self.schedule_week.isChecked():\n",
    "            if self.schedule_week_1.isChecked():\n",
    "                dayOfWeek=dayOfWeek+'0,'\n",
    "            if self.schedule_week_2.isChecked():\n",
    "                dayOfWeek=dayOfWeek+'1,'\n",
    "            if self.schedule_week_3.isChecked():\n",
    "                dayOfWeek=dayOfWeek+'2,'\n",
    "            if self.schedule_week_4.isChecked():\n",
    "                dayOfWeek=dayOfWeek+'3,'\n",
    "            if self.schedule_week_5.isChecked():\n",
    "                dayOfWeek=dayOfWeek+'4,'\n",
    "            if self.schedule_week_6.isChecked():\n",
    "                dayOfWeek=dayOfWeek+'5,'\n",
    "            if self.schedule_week_7.isChecked():\n",
    "                dayOfWeek=dayOfWeek+'6,'\n",
    "        dayOfWeek=dayOfWeek[:-1]\n",
    "        if \"my_scheduler\" not in str(dir(self)):\n",
    "            self.my_scheduler = QtScheduler(timezone=\"Asia/Taipei\")\n",
    "            self.my_scheduler.start()\n",
    "            self.my_scheduler_job_dic={}\n",
    "            \n",
    "        times = self.schedule_time.text().strip()\n",
    "        times = times + ';'\n",
    "        times = re.findall(r'(.*?);',times)\n",
    "        schedule_name = self.schedule_name.text().strip()\n",
    "        \n",
    "        for time in times:\n",
    "            x = 0\n",
    "            try:\n",
    "                time = datetime.datetime.strptime(time.strip(), \"%H:%M:%S\")\n",
    "                hour=int(time.hour)\n",
    "                minute=int(time.minute)\n",
    "                second=int(time.second)\n",
    "            except Exception as ex:\n",
    "                self.printf(\"時間剖析錯誤，請檢查輸入\", 'schedule')\n",
    "                self.schedule_create.setEnabled(True)\n",
    "                return\n",
    "            \n",
    "            self.Crontrigger = CronTrigger(timezone='Asia/Taipei', day_of_week=dayOfWeek, hour=hour, minute=minute, second=second)\n",
    "            while True:\n",
    "                try:\n",
    "                    x = x + 1\n",
    "                    idd = schedule_name+\"_\"+str(x)\n",
    "                    self.my_scheduler.add_job(self.job_do, self.Crontrigger, id=idd, args=[self.schedule_load_setting_comboBox.currentText().strip(),idd] )\n",
    "                    break\n",
    "                except:\n",
    "                    pass\n",
    "            if x>1:\n",
    "                duplicate_str = \" (排程名稱重複，已重新修改名字)\"\n",
    "            else:\n",
    "                duplicate_str = \"\"\n",
    "            self.my_scheduler_job_dic[idd]=self.schedule_load_setting_comboBox.currentText().strip()\n",
    "            self.printf(f\"{str(hour)}:{str(minute)}:{str(second)} 名稱：{str(idd)} 排程建立成功。{duplicate_str}\", 'schedule')\n",
    "\n",
    "        self.schedule_create.setEnabled(True)\n",
    "    def show_job(self):\n",
    "        self.printf(' ', 'schedule')\n",
    "        if \"my_scheduler\" in dir(self):\n",
    "            jobs=self.my_scheduler.get_jobs()\n",
    "            if len(self.my_scheduler_job_dic) ==0:\n",
    "                self.printf('當前未存在任何排程', 'schedule')\n",
    "                return\n",
    "            for job in jobs:\n",
    "                str = \"名稱: %s, 觸發時間設定: %s, 下次執行時間: %s, 執行任務: %s\" % (job.id, job.trigger, job.next_run_time, self.my_scheduler_job_dic[job.id])\n",
    "                self.printf(str, 'schedule')\n",
    "        else:\n",
    "            self.printf('當前未新增任何一個任務', 'schedule')\n",
    "            self.schedule_exec_all.setEnabled(True)\n",
    "            self.schedule_delete.setEnabled(True)\n",
    "    def delete_job(self):\n",
    "        self.printf(' ', 'schedule')\n",
    "        if len(self.my_scheduler_job_dic) > 0:\n",
    "            for i in self.my_scheduler_job_dic:\n",
    "                self.my_scheduler.remove_job(i,jobstore=None)\n",
    "            self.my_scheduler_job_dic={}\n",
    "            self.printf(\"刪除完畢\", 'schedule')\n",
    "        else:\n",
    "            self.printf(\"當前無任務\", 'schedule')\n",
    "    def exec_job(self):\n",
    "        self.printf(' ', 'schedule')\n",
    "        if len(self.my_scheduler_job_dic) > 0:\n",
    "            for ini in set(self.my_scheduler_job_dic.values()):\n",
    "                idd = [k for k, v in self.my_scheduler_job_dic.items() if v == ini][0]\n",
    "                self.job_do(ini, idd)\n",
    "    def show_job_partial(self):\n",
    "        self.printf(' ', 'schedule')\n",
    "        if self.schedule_search.text().strip() =='':\n",
    "            self.printf(\"請輸入排程名稱\", 'schedule')\n",
    "            return\n",
    "        try:\n",
    "            len(self.my_scheduler_job_dic)\n",
    "        except:\n",
    "            self.printf(\"當前未存在任何排程\", 'schedule')\n",
    "            return\n",
    "        if len(self.my_scheduler_job_dic) > 0:\n",
    "            jobs=self.my_scheduler.get_jobs()\n",
    "            for job in jobs:\n",
    "                if self.schedule_search.text().strip() in job.id :\n",
    "                    str = \"名稱: %s, 觸發時間設定: %s, 下次執行時間: %s, 執行任務: %s\" % (job.id, job.trigger, job.next_run_time, self.my_scheduler_job_dic[job.id])\n",
    "                    self.printf(str, 'schedule')\n",
    "        else:\n",
    "            self.printf(\"當前無任務\", 'schedule')\n",
    "        self.schedule_delete_search.setEnabled(True)\n",
    "        self.schedule_exec_all_search.setEnabled(True)\n",
    "    def delete_job_partial(self):\n",
    "        self.printf(' ', 'schedule')\n",
    "        if len(self.my_scheduler_job_dic) > 0:\n",
    "            deleted_list=[]\n",
    "            for job in self.my_scheduler_job_dic:\n",
    "                if self.schedule_search.text().strip() in job:\n",
    "                        self.my_scheduler.remove_job(job,jobstore=None)\n",
    "                        deleted_list.append(job)\n",
    "            [self.my_scheduler_job_dic.pop(key, None) for key in deleted_list]\n",
    "            self.printf(\"刪除完畢\", 'schedule')\n",
    "        else:\n",
    "            self.printf(\"當前無對應任務\", 'schedule')\n",
    "        self.schedule_delete_search.setEnabled(False)\n",
    "        self.schedule_search.setText('')\n",
    "    def exec_job_partial(self):\n",
    "        self.printf(' ', 'schedule')\n",
    "        if len(self.my_scheduler_job_dic) > 0:\n",
    "            exec_list = {k:v for k, v in self.my_scheduler_job_dic.items() if self.schedule_search.text().strip() in k}\n",
    "            for ini in set(exec_list.values()):\n",
    "                idd = [k for k, v in exec_list.items() if v == ini][0]\n",
    "                self.job_do(ini, idd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e75fa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from builtins import str\n",
    "if __name__ == \"__main__\":\n",
    "    ui = controller()\n",
    "    ui.MainWindow.show()\n",
    "    try:\n",
    "        sys.exit(ui.app.exec_())\n",
    "    except:\n",
    "        pass\n",
    "    del ui.app\n",
    "    del ui.MainWindow\n",
    "    del ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd40138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Qt_crawler",
   "language": "python",
   "name": "qtcrawler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
